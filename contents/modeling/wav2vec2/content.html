
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Wav2Vec 2.0 &#8212; Machine Learning Notes</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://note.notmlprojects.com/contents/modeling/wav2vec2/content.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Metrics" href="../../metrics/content.html" />
    <link rel="prev" title="Vision Transformer" href="../vision_transformer/content.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-SN82SMEHZ2"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-SN82SMEHZ2');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Concepts
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../content.html">
   Modelings
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../res_net/content.html">
     Residual Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mobile_net/content.html">
     MobileNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../efficient_net/content.html">
     EfficientNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vision_transformer/content.html">
     Vision Transformer
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Wav2Vec 2.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../metrics/content.html">
   Metrics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../metrics/angular_similarity/content.html">
     Angular Similarity
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tips_and_tricks/content.html">
   Tips and Tricks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tips_and_tricks/nan_on_training/content.html">
     NaN on Training
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/content.html">
   Applications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/wav2vec2_phoneme/content.html">
     Wav2Vec2 for Phoneme
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tools and Frameworks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tools_and_frameworks/tensorflow/content.html">
   Tensorflow
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tools_and_frameworks/tensorflow/demystifying_tf_data/content.html">
     Demystifying tf.Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tools_and_frameworks/sagemaker/content.html">
   AWS Sagemaker
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../projects/speech_rehearsal/content.html">
   Speech Rehearsal
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/contents/modeling/wav2vec2/content.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#concept">
   Concept
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset">
   Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strengths-and-limitations">
   Strengths and Limitations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#strengths">
     Strengths
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations">
     Limitations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Wav2Vec 2.0</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#concept">
   Concept
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset">
   Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strengths-and-limitations">
   Strengths and Limitations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#strengths">
     Strengths
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations">
     Limitations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="wav2vec-2-0">
<h1>Wav2Vec 2.0<a class="headerlink" href="#wav2vec-2-0" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://arxiv.org/abs/2006.11477">Wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski. et al, 2020)</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Based on the Transformer model, Wav2Vec 2.0 is trained using a self-supervised method to predict masked audio segments.</p></li>
<li><p>Perform well in low-resource multilingual languages.</p></li>
</ul>
</div>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">#</a></h2>
<p>There are two main motivations for this paper:</p>
<p><strong>1. Can there be a better way to train the wave-to-vec model without any label data?</strong></p>
<p>If we compare this to training text-based language model (LM), working with text is much easier to do self-supervised learning. Commonly, a token is masked and the model is used to guess what that masked word is, e.g., the BERT model. Alternatively, given <span class="math notranslate nohighlight">\(n\)</span> tokens, the model is trained to predict the next one. However, in audio, things are slightly more complicated, specifically, it’s no longer about predicting a token but predicting a sequence of the audio segment.</p>
<p><strong>2. Can the model benefit from training on multilingual data?</strong></p>
<p>If we have the same model architecture but are trained on two different types of data (monolingual and multilingual), which one is more beneficial for the downstream task?</p>
</section>
<section id="concept">
<h2>Concept<a class="headerlink" href="#concept" title="Permalink to this headline">#</a></h2>
<p>The core of Wav2Vec2 is based on the standard Transformer model. It’s one of the main building blocks of this architecture. The main difference is its input and the loss function.</p>
<figure class="align-center" id="wav2vec-2-0-transformer-architecture">
<a class="reference internal image-reference" href="../../../_images/model.png"><img alt="../../../_images/model.png" src="../../../_images/model.png" style="width: 700px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Wav2Vec 2.0 Transformer Architecture</span><a class="headerlink" href="#wav2vec-2-0-transformer-architecture" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><strong>Preprocessing:</strong> This model takes in raw audio. No audio preprocessor (or Fourier transform) is required.</p></li>
<li><p><strong>Latent Representation:</strong> Raw audio <span class="math notranslate nohighlight">\(X\)</span> is split into chunks (with some overlappings) and fed into CNN <span class="math notranslate nohighlight">\(Z\)</span> to extract its latent representation. For instance at chunk <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(x_i \rightarrow z_i\)</span>.</p></li>
<li><p><strong>Contextual Representation:</strong> This latent representation <span class="math notranslate nohighlight">\(z_i\)</span> along with <span class="math notranslate nohighlight">\(z_j\)</span> at other time steps are fed into the standard Transformer to obtain contextual representation <span class="math notranslate nohighlight">\(c_i\)</span>. What this means is that the vector <span class="math notranslate nohighlight">\(c_i\)</span> captures and is aware of nearby audio chunks.</p></li>
<li><p><strong>Product Quantization:</strong> The same <span class="math notranslate nohighlight">\(z_i\)</span> is also get discretized into <span class="math notranslate nohighlight">\(l_i\)</span>. In other words, we try to put a label onto <span class="math notranslate nohighlight">\(z_i\)</span>.</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(q\)</span> has two modules where each element has a vocab size of 320.</p></li>
<li><p>This corresponds to 102.4K combinations of code words.</p></li>
<li><p>This discretize module uses <strong>Gumbel-Softmax</strong> to allow the flow of differentiation because the regular <strong>argmax</strong> function is indifferentiable.</p></li>
<li><p>With the discretized <span class="math notranslate nohighlight">\(l_i\)</span>, it is projected back into a vector and concatenated (since we are having two modules for each <span class="math notranslate nohighlight">\(l\)</span>) into a vector <span class="math notranslate nohighlight">\(q_i\)</span> of the same size as <span class="math notranslate nohighlight">\(c_i\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Masked Prediction:</strong> Remember that the model does not see <span class="math notranslate nohighlight">\(z_i\)</span> because <span class="math notranslate nohighlight">\(z_i\)</span> is masked and instead obtains <span class="math notranslate nohighlight">\(c_i\)</span> from its surrounding context? Now model needs to pick which <span class="math notranslate nohighlight">\(q_i\)</span> is the most relevant to the embedding <span class="math notranslate nohighlight">\(c_i\)</span>?</p>
<ul>
<li><p>The comparison between <span class="math notranslate nohighlight">\(c_i\)</span> and <span class="math notranslate nohighlight">\(q_i\)</span> is done using a simple cosine similarity function.</p></li>
</ul>
</li>
</ul>
<figure class="align-center" id="contrastive-loss-function">
<a class="reference internal image-reference" href="../../../_images/contrastive_loss.png"><img alt="../../../_images/contrastive_loss.png" src="../../../_images/contrastive_loss.png" style="width: 500px;" /></a>
</figure>
<ul class="simple">
<li><p><strong>Diverse Discretize</strong>: There can be cases where the model does not utilize all the vocabulary in the <span class="math notranslate nohighlight">\(Q\)</span> module. It might just pick a subset of <span class="math notranslate nohighlight">\(Q\)</span> again and again. To combat this problem, they include a diversity loss function. Essentially, it penalizes when the model is very certain of a particular code label. The higher the entropy, the bigger loss value is.</p></li>
</ul>
<figure class="align-center" id="diversity-loss-function">
<a class="reference internal image-reference" href="../../../_images/diversity_func.png"><img alt="../../../_images/diversity_func.png" src="../../../_images/diversity_func.png" style="width: 500px;" /></a>
</figure>
<ul class="simple">
<li><p><strong>Extra 💬</strong>: If the model ends up comparing vector <span class="math notranslate nohighlight">\(c_i\)</span> with another vector <span class="math notranslate nohighlight">\(q_i\)</span>, why need to go through all those quantization processes? Why don’t we just use <span class="math notranslate nohighlight">\(z_i\)</span> instead?</p>
<ul>
<li><p>If we compare with <span class="math notranslate nohighlight">\(z_i\)</span>, that would mean we want the model to output exactly the same as the latent representation module (<span class="math notranslate nohighlight">\(Z\)</span>). This would just turn this Transformer module into an identity function.</p></li>
</ul>
</li>
</ul>
</section>
<section id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">#</a></h2>
<p>The model was experimented with and trained on Librispeech (960 hours of audio) or LibriVox (53.2K hours of audio). Both datasets are not merged. Based on <a class="reference external" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/">this blog post</a>, it seems that the publicly released version of Wav2Vec 2.0 is pre-trained on <strong>LibriVox</strong> dataset.</p>
</section>
<section id="strengths-and-limitations">
<h2>Strengths and Limitations<a class="headerlink" href="#strengths-and-limitations" title="Permalink to this headline">#</a></h2>
<section id="strengths">
<h3>Strengths<a class="headerlink" href="#strengths" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>This self-supervised learning approach is successful. Fine-tuning this on the benchmark dataset (ASR) outperforms the existing models.</p></li>
<li><p>The fine-tuning does not require that much data. This enables the downstream task on low-resource language to be efficient. It can go down to 10 hours or even 1 hour.</p>
<ul>
<li><p>💬 We try to fine-tune this on the Khmer language recognition task using only around 3 hours. And the performance is mindblowing, given using low resource language.</p></li>
</ul>
</li>
</ul>
</section>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The limitation of this model is not properly discussed in the paper.</p></li>
</ul>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>We can now apply self-supervised learning to raw audio data.</p></li>
<li><p>Fine-tuned Wav2Vec 2.0 performs well on both high and low-resource languages (down to 10 hours). It can also go down to 1 hour. Obviously, it wouldn’t be that good compared to having more data, but it’s feasible.</p></li>
</ul>
<br/>
<hr/>
<br/>
<p>💬 denotes <strong>opinion</strong> and is not from the paper.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./contents/modeling/wav2vec2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../vision_transformer/content.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Vision Transformer</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../metrics/content.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Metrics</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Vitou Phy<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>